{
 "cells": [
  {
   "cell_type": "raw",
   "id": "e6b689a8",
   "metadata": {},
   "source": [
    "pip install --upgrade numpy\n",
    "pip install transformer\n",
    "conda create -n huggingface_env python=3.10 -y\n",
    "conda activate huggingface_env\n",
    "pip install huggingface_hub[hf_xet]\n",
    "pip install numpy==1.26.2 tensorflow==2.18.0 transformers\n",
    "pip install tensorflow-intel==2.18.0 numpy==1.26.2\n",
    "pip install gensim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13923ea2",
   "metadata": {},
   "source": [
    "# Hugging Face Transformers for NLP Tasks\n",
    "\n",
    "---\n",
    "\n",
    "## What is Hugging Face?\n",
    "\n",
    "[Hugging Face](https://huggingface.co/) provides:\n",
    "\n",
    "- `transformers`: State-of-the-art pre-trained models for NLP (and beyond).\n",
    "- `datasets`: Ready-to-use NLP datasets.\n",
    "- `tokenizers`: Fast and customizable tokenization.\n",
    "\n",
    "---\n",
    "\n",
    "## Installation\n",
    "\n",
    "pip install transformers\n",
    "pip install torch  # or tensorflow, depending on backend\n",
    "\n",
    "\n",
    "\n",
    "## Common NLP Tasks with Hugging Face\n",
    "\n",
    "| Task                           | Description                               | Model Example       |\n",
    "| ------------------------------ | ----------------------------------------- | ------------------- |\n",
    "| Text Classification            | Classify text into categories             | BERT, DistilBERT    |\n",
    "| Named Entity Recognition (NER) | Identify entities in text                 | BERT, RoBERTa       |\n",
    "| Question Answering             | Extract answer from a given context       | BERT, ALBERT        |\n",
    "| Summarization                  | Summarize long text into key points       | BART, T5            |\n",
    "| Translation                    | Translate text between languages          | MarianMT, mBART     |\n",
    "| Text Generation                | Autocomplete or continue text generation  | GPT-2, GPT-3, LLaMA |\n",
    "| Sentiment Analysis             | Detect sentiment (positive/negative/etc.) | DistilBERT, BERT    |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31019565",
   "metadata": {},
   "source": [
    "**The pipeline() function is the simplest way to use Hugging Face models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd69f2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.9959076642990112}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Explicitly specify the model name\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "# Load the sentiment analysis pipeline with the specified model\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model_name, tokenizer=model_name)\n",
    "\n",
    "# Sentiment analysis\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "print(classifier(\"Suyashi hates coding\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6626f1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "C:\\Users\\Suyashi144893\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'PER', 'score': 0.9978213, 'word': 'Ashi', 'start': 11, 'end': 15}, {'entity_group': 'LOC', 'score': 0.9997433, 'word': 'India', 'start': 30, 'end': 35}]\n"
     ]
    }
   ],
   "source": [
    "# Named Entity Recognition\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "print(ner(\"My name is Ashi and I live in India.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7db22e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n",
      "C:\\Users\\Suyashi144893\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\question_answering.py:390: FutureWarning: Passing a list of SQuAD examples to the pipeline is deprecated and will be removed in v5. Inputs should be passed using the `question` and `context` keyword arguments instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9746261239051819, 'start': 30, 'end': 35, 'answer': 'India'}\n"
     ]
    }
   ],
   "source": [
    "# Question Answering\n",
    "qa = pipeline(\"question-answering\")\n",
    "result = qa({\n",
    "    'question': 'Where do I live?',\n",
    "    'context': 'My name is Ashi and I live in India.'\n",
    "})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ebf7ede",
   "metadata": {},
   "source": [
    "# Summarization\n",
    "summarizer = pipeline(\"summarization\")\n",
    "text = \"\"\"Life is a journey, a path unknown,\n",
    "A road we walk, yet not alone.\n",
    "With dreams as maps and hope as light,\n",
    "We trek through day and rest by night.\n",
    "\n",
    "Some steps are smooth, some steep and rough,\n",
    "At times the way feels long and tough.\n",
    "But every turn and twist we face,\n",
    "Reveals new strength, unveils new grace.\n",
    "\n",
    "We meet some souls who walk awhile,\n",
    "They teach us love, they make us smile.\n",
    "And others pass like fleeting air,\n",
    "Yet leave a mark that lingers there.\n",
    "\n",
    "So walk with courage, heart held high,\n",
    "Beneath the storm or open sky.\n",
    "For life’s a journey — not the end, but why..\"\"\"\n",
    "print(summarizer(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12544443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google-t5/t5-base and revision a9723ea (https://huggingface.co/google-t5/t5-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'Bonjour, comment êtes-vous?'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Translation\n",
    "translator = pipeline(\"translation_en_to_fr\")\n",
    "print(translator(\"Hello, how are you?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e3de60",
   "metadata": {},
   "source": [
    "### Under the Hood: Model & Tokenizer Loading\n",
    "You can manually load the model/tokenizer if you want finer control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a271ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "inputs = tokenizer(\"I love this product!\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits\n",
    "prediction = torch.argmax(logits)\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bab40dd",
   "metadata": {},
   "source": [
    "## Advantages of Hugging Face Pipelines\n",
    "Quick setup\n",
    "\n",
    "Pre-trained models ready for use\n",
    "\n",
    "Handles tokenization, model inference, and decoding internally\n",
    "\n",
    "Easy to switch models by changing model name\n",
    "\n",
    "### Where to Find Models\n",
    "- Browse thousands of models at https://huggingface.co/models\n",
    "\n",
    "## Summary\n",
    "- Hugging Face makes using SOTA NLP models easy with pipeline().\n",
    "\n",
    "- Supports a wide variety of tasks: classification, NER, QA, summarization, etc.\n",
    "\n",
    "- You can dig deeper by using tokenizers and model classes directly.\n",
    "\n",
    "- Easily switch between models with AutoModel and AutoTokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60facd15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
