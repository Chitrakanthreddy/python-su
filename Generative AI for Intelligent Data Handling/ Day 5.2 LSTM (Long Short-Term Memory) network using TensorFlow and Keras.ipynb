{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f47d602f",
   "metadata": {},
   "source": [
    "## LSTM (Long Short-Term Memory) is a type of recurrent neural network (RNN) designed to address the problem of capturing long-term dependencies in sequential data.\n",
    "- It consists of a memory cell that can maintain information over long sequences, controlled by three gates: forget gate, input gate, and output gate.\n",
    "- The forget gate decides what information to discard from the cell state.\n",
    "- The input gate decides what new information to store in the cell state.\n",
    "- The output gate decides what information to output from the cell state.\n",
    "- LSTM's ability to retain and forget information over long periods makes it effective for tasks involving sequential data with long-term dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f81caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Generate some random data for demonstration\n",
    "# Input sequence: [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "# Output sequence: [0.6, 0.7, 0.8, 0.9, 1.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82fff456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input sequence\n",
    "X = np.array([[[0.1], [0.2], [0.3], [0.4], [0.5]]])\n",
    "\n",
    "# Define output sequence\n",
    "y = np.array([[0.6, 0.7, 0.8, 0.9, 1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab2f22d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and build the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(50, input_shape=(5, 1)),  # 50 units in LSTM layer\n",
    "    Dense(5)  # Output layer\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25759ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 50)                10400     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 255       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,655\n",
      "Trainable params: 10,655\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d020e214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6636\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6515\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6395\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6276\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6158\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6040\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5922\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5803\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5684\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5565\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5444\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5321\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5197\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.5071\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4942\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4810\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4675\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4537\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4394\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4247\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4096\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.3939\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.3776\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3607\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.3432\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3251\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3062\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2867\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.2665\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.2456\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2242\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2022\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.1798\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1572\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.1346\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.1122\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.0904\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0697\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0506\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0336\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0196\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0092\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0030\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0013\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0038\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0096\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0169\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0235\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0278\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0289\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0270\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0230\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0178\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0125\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0078\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0041\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0017\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.6679e-04\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 3.3635e-05\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 4.0104e-04\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0012\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0022\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0032\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0040\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0046\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0049\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0049\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0046\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0041\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0035\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0028\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.0021\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.0014\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 8.5391e-04\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 4.3130e-04\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.6618e-04\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.5138e-05\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.6724e-05\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.9566e-04\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 3.6887e-04\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 5.5240e-04\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.0809e-04\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 8.0866e-04\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 8.4051e-04\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 8.0377e-04\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 7.1000e-04\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 5.7829e-04\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 4.3067e-04\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 2.8802e-04\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.6686e-04\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.7621e-05\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.4196e-05\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 4.6745e-06\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.2784e-05\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 3.9677e-05\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.5722e-05\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 1.1201e-04\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.4147e-04\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.5949e-04\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.6409e-04\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Predictions:\n",
      "[[0.5899611  0.69120526 0.7883316  0.88775873 0.9822645 ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=100, verbose=1)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Print predictions\n",
    "print(\"Predictions:\")\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b121b42",
   "metadata": {},
   "source": [
    "Predictions:\n",
    "[[0.5899611  0.69120526 0.7883316  0.88775873 0.9822645 ]]\n",
    "\n",
    "##Actual \n",
    "\n",
    "y = np.array([[0.6, 0.7, 0.8, 0.9, 1.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240f2481",
   "metadata": {},
   "source": [
    "## Quick Practice Generate an input sequence consisting of Even numbers and predict the next odd number in the sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe3e05a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Function to generate an input sequence of even numbers\n",
    "def generate_input_sequence(start, length):\n",
    "    sequence = [2 * i for i in range(start, start + length)]\n",
    "    return np.array(sequence)\n",
    "\n",
    "# Generate input sequence with 100 rows\n",
    "input_sequence = generate_input_sequence(start=1, length=100)\n",
    "\n",
    "# Output sequence (next even number in the sequence)\n",
    "output_sequence = input_sequence[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2b37966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2,   4,   6,   8,  10,  12,  14,  16,  18,  20,  22,  24,  26,\n",
       "        28,  30,  32,  34,  36,  38,  40,  42,  44,  46,  48,  50,  52,\n",
       "        54,  56,  58,  60,  62,  64,  66,  68,  70,  72,  74,  76,  78,\n",
       "        80,  82,  84,  86,  88,  90,  92,  94,  96,  98, 100, 102, 104,\n",
       "       106, 108, 110, 112, 114, 116, 118, 120, 122, 124, 126, 128, 130,\n",
       "       132, 134, 136, 138, 140, 142, 144, 146, 148, 150, 152, 154, 156,\n",
       "       158, 160, 162, 164, 166, 168, 170, 172, 174, 176, 178, 180, 182,\n",
       "       184, 186, 188, 190, 192, 194, 196, 198, 200])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4e38231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4,   6,   8,  10,  12,  14,  16,  18,  20,  22,  24,  26,  28,\n",
       "        30,  32,  34,  36,  38,  40,  42,  44,  46,  48,  50,  52,  54,\n",
       "        56,  58,  60,  62,  64,  66,  68,  70,  72,  74,  76,  78,  80,\n",
       "        82,  84,  86,  88,  90,  92,  94,  96,  98, 100, 102, 104, 106,\n",
       "       108, 110, 112, 114, 116, 118, 120, 122, 124, 126, 128, 130, 132,\n",
       "       134, 136, 138, 140, 142, 144, 146, 148, 150, 152, 154, 156, 158,\n",
       "       160, 162, 164, 166, 168, 170, 172, 174, 176, 178, 180, 182, 184,\n",
       "       186, 188, 190, 192, 194, 196, 198, 200])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sequence = input_sequence[1:]\n",
    "output_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53378e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Prediction (Next Even Number): 198\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Preprocess the data\n",
    "def create_dataset(input_sequence, output_sequence, time_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(input_sequence) - time_steps):\n",
    "        X.append(input_sequence[i:i+time_steps])\n",
    "        y.append(output_sequence[i])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "time_steps = 3  # Number of time steps (length of input sequence for each training example)\n",
    "X, y = create_dataset(input_sequence, output_sequence, time_steps)\n",
    "\n",
    "# Define the RNN model\n",
    "model = Sequential([\n",
    "    LSTM(50, activation='relu', input_shape=(time_steps, 1)),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Reshape input for LSTM\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=100, verbose=0)\n",
    "\n",
    "# Test data for final prediction\n",
    "test_data = np.array([input_sequence[-3:]])  # Taking the last three elements of the input sequence\n",
    "\n",
    "# Generate the output sequence\n",
    "def generate_prediction(model, test_data):\n",
    "    x_input = test_data.reshape((1, time_steps, 1))\n",
    "    y_pred = model.predict(x_input, verbose=0)\n",
    "    return int(y_pred[0][0])\n",
    "\n",
    "# Final prediction\n",
    "next_even_number = generate_prediction(model, test_data)\n",
    "\n",
    "print(\"Final Prediction (Next Even Number):\", next_even_number)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
